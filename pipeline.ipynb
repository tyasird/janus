{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3><p style=\"text-align: center;\">JANUS - Joint ANalysis for augmentation of clUSter specificity</p></h3>\n",
    "<p style=\"text-align: center;\">DepMap and subset of DepMap samples</p>\n",
    "<p style=\"text-align: center;\">Updated: 26/05/2023</p>\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Package dependencies \n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import norm, pearsonr\n",
    "import helpers as h\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "import os\n",
    "import slugify\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "import plotly.graph_objects as go\n",
    "import kaleido\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data preparation and preprocessing   \n",
    "===\n",
    "> X12 = Achilles_gene_effect_20Q2 / ~700 samples      \n",
    "> X1 = DepMap - Cancer Samples  \n",
    "> X2 = Subset of DepMap for cancer specific samples / 27 subset   \n",
    "\n",
    "Load the DepMap data from the CSV file __Achilles_gene_effect_20Q2.csv__ and perform preprocessing steps.  \n",
    "Apply z-score normalization for X12, since other X1 and X2 is the subset of this dataset, we do not need to apply separately.    \n",
    "We delete paranteses from DepMap dataset.   \n",
    "There are some empty cells, we drop this cells sample wise. It does not effect gene size, reduceses sample size a bit.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./input/Achilles_gene_effect_20Q2.csv', index_col=0).T\n",
    "df.index = [i.split(' ')[0] for i in df.index] # type: ignore\n",
    "dfnorm = (df - df.mean())/df.std(ddof=0)\n",
    "df = dfnorm.T.dropna().T"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read Terms from Database (GOBP, Complex, Pathway)\n",
    "===\n",
    "\n",
    "Load the terms data from the provided CSV file and perform filtering based on the length of the complexes.      \n",
    "A set of unique genes is extracted from the terms data and the input DataFrame.    \n",
    "Common genes between the terms and DepMap are identified.      \n",
    "The terms data is filtered to include only complexes with lengths greater than 2.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms, terms_uniq_genes = h.read_terms(\"./input/terms/data_complex.csv\")\n",
    "# common genes with DepMap and TermsDB\n",
    "common_genes = list(set(terms_uniq_genes) & set(df.index))\n",
    "# filter complexes\n",
    "#terms = terms.query('Length > 2').reset_index(drop=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DepMap sample annotation\n",
    "===\n",
    "\n",
    "Load the disease data from the provided file and perform filtering based on inclusion criteria.     \n",
    "For the annotation **Achilles_gene_effect_20Q2_info** file is used.   \n",
    "For the results, common and per disease directories are created. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diseases = pd.read_excel('./input/types.xlsx')\n",
    "diseases = diseases[diseases.include ==1 ]\n",
    "info = pd.read_csv('./input/Achilles_gene_effect_20Q2_info.csv',index_col=0)\n",
    "result_dir = 'C:/Users/yd/Desktop/projects/janus/results/per_disease/'\n",
    "common_dir = os.path.join(result_dir,'common')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DO annotation for X12 once, copy this annotation to all diseases. \n",
    "----\n",
    "\n",
    "__This area only changes when TERMS are changed !__  \n",
    "We perform an annotation process for the dataset X12 (DepMap) once, considering the absence of gene pairs in the Terms database. The gene count remains constant throughout this process, only changing when the terms are modified. To ensure consistency, we use the same annotation obtained for X12 to annotate X1 and X2.\n",
    "\n",
    "In this section, we perform the common analysis for the terms.   \n",
    "The commented code block represents the initial analysis that needs to be executed when the terms are changed.   \n",
    "It calculates the correlation matrix (x12), converts it to a half-matrix format (f12), creates a binary matrix (s12),   \n",
    "runs gene-level annotation in parallel (annotated12), and performs precision-recall analysis (pra12).  \n",
    "The resulting dataframes are saved in the common directory. In subsequent runs, when the x12 and pra12 files exist in the common directory, the code block is skipped, and the saved data is loaded into the respective dataframes (x12, pra12), as well as the necessary subsets (annotated12, f12, s12).    \n",
    "The resulting dataframes (x12, pra12, annotated12, f12, s12) are available for further analysis and processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this area only changes when TERMS changed\n",
    "#x12 = h.perform_corr(df)\n",
    "#x12.to_parquet(os.path.join(common_dir,'x12.p'))\n",
    "#f12 = x12.loc[common_genes,common_genes].copy()\n",
    "#h.convert_full_to_half_matrix(f12)\n",
    "#s12 = h.make_binary(f12)\n",
    "#annotated12 = h.run_annotation_parallel(s12,terms, 10, 10)\n",
    "#pra12 = h.pr_analysis(annotated12)\n",
    "#pra12.to_parquet(os.path.join(common_dir,'pra12.p')) \n",
    "# this area only changes when TERMS changed\n",
    "\n",
    "# this area only changes when TERMS changed.\n",
    "if os.path.isfile(os.path.join(common_dir,'x12.p')):\n",
    "     x12 = pd.read_parquet(os.path.join(common_dir,'x12.p'))\n",
    "     pra12 = pd.read_parquet(os.path.join(common_dir,'pra12.p'))\n",
    "     annotated12 = pra12.drop(['prediction','tp','precision','recall'],axis=1)\n",
    "     f12 = x12.loc[common_genes,common_genes].copy()\n",
    "     h.convert_full_to_half_matrix(f12)\n",
    "     s12 = h.make_binary(f12)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation and PR analysis [each disease]\n",
    "---\n",
    "\n",
    "We iterate over each row in the diseases dataset to perform disease correlation analysis. For each row, we retrieve the correlation matrices x1 and x2.\n",
    "Next, we perform a quick precision-recall analysis for x1 and x2. This analysis considers the common_genes and the pre-existing annotations in annotated12. The results of the analysis are stored in the variables pra1 and pra2, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,row in tqdm(diseases.iterrows()):  \n",
    "    x1, x2 = h.get_disease_corr_matrix(df, row.disease)\n",
    "    pra1 = h.pr_analysis_quick(x1, common_genes, annotated12, row.disease, 'pra1.p')\n",
    "    pra2 = h.pr_analysis_quick(x2, common_genes, annotated12, row.disease, 'pra2.p')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per-Complex PR Analysis [for DepMap]\n",
    "---\n",
    "\n",
    "Perform this analysis for each row (complex/pathway/GOBP) \n",
    "- check how many genes exist in genome (because some complex genes may not be in the dataset)\n",
    "- contunie analysis if checked gene count is above 2 (if it is not, assign set NAN)\n",
    "- Filter correlation matrix [complex_genes, genome_genes]\n",
    "- convert to pairwise\n",
    "- drop mirror pairs A,B and B,A (otherwise we will get double TP count)\n",
    "- sort pcc score of pairs\n",
    "\n",
    "Calculation of TP, Precision, Recall\n",
    "\n",
    "- TP: Check sorted values in order, If it is anottated in the Terms database it is TP\n",
    "- Precision: TP / Index\n",
    "- Recall: TP / Number of Total TP\n",
    "\n",
    "After finding of Precision & Recall, calculate AUC score.   \n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.auc.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc12 = terms.set.progress_apply(lambda g: h.pra_single_complex(x12, common_genes, g, 3))\n",
    "score, n_gene_used = list(zip(*auc12))\n",
    "terms['n_gene_used'] = n_gene_used\n",
    "terms['auc12'] = score\n",
    "terms = terms.drop(['ID','list','set'],axis=1)\n",
    "#terms.to_parquet(os.path.join(result_dir, common_dir, 'per_complex_12.p'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per-Complex PR Analysis [each disease]\n",
    "---\n",
    "Performs Per-Complex PR Analysis for each disease. Since DepMap dataset is common for each disease, we only calculate for X1 and X2.  \n",
    "Loads the terms and unique genes from a CSV file.    \n",
    "Calculates disease-specific correlation matrices.    \n",
    "Calculates the Area Under the Curve (AUC) for each complex in the terms dataset based on the correlation matrices.    \n",
    "Updates the terms dataset with the AUC scores.    \n",
    "Saves the modified terms dataset as a Parquet file.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,row in tqdm(diseases.iterrows()):  \n",
    "    terms, terms_uniq_genes = h.read_terms(\"./input/terms/data_complex.csv\")\n",
    "\n",
    "    x1, x2 = h.get_disease_corr_matrix(df, row.disease)\n",
    "    auc1 = terms.set.progress_apply(lambda g: h.pra_single_complex(x1, common_genes, g, 3))\n",
    "    auc2 = terms.set.progress_apply(lambda g: h.pra_single_complex(x2, common_genes, g, 3))\n",
    "    \n",
    "    score1, n_gene_used = list(zip(*auc1))\n",
    "    score2, n_gene_used = list(zip(*auc2))\n",
    "    terms['auc1'] = score1\n",
    "    terms['auc2'] = score2\n",
    "    terms = terms.drop(['ID','list','set'],axis=1)\n",
    "    terms.to_parquet(os.path.join(result_dir, slugify.slugify(row.disease), 'per_complex_1and2.p'))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform Correlation Contribution Formula [each disease]\n",
    "---\n",
    "\n",
    "Performs contribution analysis for each disease in the diseases dataset.   \n",
    "Loop over the diseases.  \n",
    "Create a save directory based on the disease name.  \n",
    "Retrieve separated datasets specific to the disease.  \n",
    "Determine the size of the smaller dataset.  \n",
    "Merge the datasets and perform partial correlation analysis.  \n",
    "Save the contribution analysis results as Parquet files.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,row in tqdm(diseases.iterrows()):  \n",
    "    print(f'{row.disease} | contribution analysis is started..' )\n",
    "    save_dir = os.path.join(result_dir, slugify.slugify(row.disease), 'contr')\n",
    "    os.makedirs(save_dir,exist_ok=True)\n",
    "    d1, d2 = h.get_separated_datasets(df, row.disease)\n",
    "    n_small_set = d2.shape[1]\n",
    "    dfmer = pd.merge(d2,d1,left_index=True,right_index=True)\n",
    "    contr_big, contr_small, _, _, denom = h.partial_corr(dfmer, n_small_set)\n",
    "    contr_big.to_parquet(os.path.join(save_dir, 'contr_big.p'))\n",
    "    contr_small.to_parquet(os.path.join(save_dir, 'contr_small.p'))\n",
    "    denom.to_parquet(os.path.join(save_dir, 'denom.p'))  \n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCC mean of Complex Genes\n",
    "---\n",
    "\n",
    "For each row (complex/pathway/GOBP) calculate mean of PCC values of given genes   \n",
    "(i.e. if complex has 5 genes, get those 5 genes correlation from big correlation matrix which is 10 gene pairs. ((5*5) - 5) / 2)\n",
    "\n",
    "- remove self correlations\n",
    "- remove mirror pairs correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_disease = ['Sarcoma','Pancreatic Cancer','Neuroblastoma']\n",
    "\n",
    "x12 = pd.read_parquet(f'./results/per_disease/common/x12.p')\n",
    "x12 = h.convert_full_to_half_matrix(x12)\n",
    "per_complex_12 = pd.read_parquet(f'./results/per_disease/common/per_complex_12.p')\n",
    "\n",
    "for k,row in tqdm(diseases.iterrows()):  \n",
    "\n",
    "    # if row.disease not in selected_disease:\n",
    "    #     continue\n",
    "\n",
    "    print(row.disease)\n",
    "    terms, terms_uniq_genes = h.read_terms(\"./input/terms/data_complex.csv\")\n",
    "\n",
    "    x1 = pd.read_parquet(f'./results/per_disease/{row.slug}/x1.p')\n",
    "    x2 = pd.read_parquet(f'./results/per_disease/{row.slug}/x2.p')\n",
    "    contr_small = pd.read_parquet(f'./results/per_disease/{row.slug}/contr/contr_small.p')\n",
    "    contr_big = pd.read_parquet(f'./results/per_disease/{row.slug}/contr/contr_big.p')\n",
    "    x1 = h.convert_full_to_half_matrix(x1)\n",
    "    x2 = h.convert_full_to_half_matrix(x2)\n",
    "    per_complex_1and2 = pd.read_parquet(f'./results/per_disease/{row.slug}/per_complex_1and2.p')\n",
    "\n",
    "    data = {\n",
    "      'x12': x12,\n",
    "      'x1': x1,\n",
    "      'x2': x2,\n",
    "      'contr_small': contr_small,\n",
    "      'contr_big': contr_big,        \n",
    "    }\n",
    "\n",
    "    for data_var,v in tqdm(data.items()):    \n",
    "        df = v.copy()\n",
    "        for k,r in tqdm(terms.iterrows()):\n",
    "            terms.at[k,data_var] = h.get_mean_selected_genes(r.set, df, 3)\n",
    "\n",
    "    terms['pr_auc_x1'] = per_complex_1and2.auc1\n",
    "    terms['pr_auc_x2'] = per_complex_1and2.auc2\n",
    "    terms['pr_auc_x12'] = per_complex_12.auc12\n",
    "\n",
    "    terms.to_parquet(f'./results/per_disease/{row.slug}/mean.p')\n",
    "    terms.drop(['list','set'],axis=1).to_csv(f'./results/per_disease/{row.slug}/mean.csv',na_rep='NA')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scatter plot of AUC1 vs AUC2 [each disease]\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generates a scatter plot using Plotly for each disease in the DepMap. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_disease = ['Sarcoma','Pancreatic Cancer','Neuroblastoma']\n",
    "selected_disease = ['Myeloma']\n",
    "\n",
    "for k,row in tqdm(diseases.iterrows()): \n",
    "\n",
    "    # if row.disease not in selected_disease:\n",
    "    #     continue   \n",
    "    \n",
    "    terms = pd.read_parquet(f'./results/per_disease/{row.slug}/mean.p')\n",
    "    terms = terms[~terms.x1.isna()]\n",
    "    terms = terms.drop(['list','set'],axis=1)\n",
    "    terms['hue'] = 0\n",
    "    terms = terms.sort_values('contr_small', ascending=False)\n",
    "    terms.iloc[:10, terms.columns.get_loc('hue')] = 2 \n",
    "    terms = terms.sort_values('contr_big', ascending=False)\n",
    "    terms.iloc[:10, terms.columns.get_loc('hue')] = 1 \n",
    "    terms['hue2'] = terms.hue.map({0: 'normal', 1:'big_contr_extreme_10', 2:'small_contr_extreme_10'})\n",
    "    # define legend for extreme values\n",
    "    terms['legend'] = np.where(terms.hue != 0, terms['Name'].apply(lambda x: x[:20]), '')\n",
    " \n",
    "\n",
    "    config = {'staticPlot': True}\n",
    "    fig = go.Figure()\n",
    "\n",
    "    fig = px.scatter(terms, x='pr_auc_x1', y='pr_auc_x2', color='hue2', \n",
    "    title=f'{row.disease} | n_sample: {row.n_sample}', color_discrete_map={\n",
    "                 \"normal\": \"grey\",\"small_contr_extreme_10\": \"blue\",\"big_contr_extreme_10\": \"black\",\n",
    "    })\n",
    "    fig.add_shape( type=\"line\", x0=0, y0=0, x1=1,y1=1, line=dict(color=\"Grey\",width=1) )\n",
    "\n",
    "    fig.update_layout(\n",
    "        autosize=False,width=900, height=600,\n",
    "        title_x=0.5,\n",
    "        font_color=\"black\",\n",
    "        title_font_color=\"black\",\n",
    "    )\n",
    "\n",
    "    fig.update_layout(\n",
    "        xaxis=dict(domain = [0, 0.65],  anchor = 'y1'),\n",
    "        legend=dict(\n",
    "            title=\" Contribution score\",\n",
    "            yanchor=\"top\",\n",
    "            y=0.99,\n",
    "            xanchor=\"right\",\n",
    "            x=0.92),\n",
    "            annotations=[\n",
    "                go.layout.Annotation(\n",
    "                    text=\"..<br>\".join([i for i in terms[terms.hue == 1].legend]),\n",
    "                    align='left',\n",
    "                    showarrow=False,\n",
    "                    xref='paper',\n",
    "                    yref='paper',\n",
    "                    x=0.92,\n",
    "                    y=0.58,\n",
    "                    bordercolor='black',\n",
    "                    borderwidth=1,\n",
    "                    width=180,\n",
    "                ),\n",
    "                go.layout.Annotation(\n",
    "                    text=\"..<br>\".join([i for i in terms[terms.hue == 2].legend]),\n",
    "                    align='left',\n",
    "                    showarrow=False,\n",
    "                    xref='paper',\n",
    "                    yref='paper',\n",
    "                    x=0.92,\n",
    "                    y=0.0,\n",
    "                    bordercolor='blue',\n",
    "                    borderwidth=1,\n",
    "                    width=180,\n",
    "                )\n",
    "            ],\n",
    "\n",
    "    )\n",
    "\n",
    "    fig.show(config=config)\n",
    "    fig.write_image(f'{row.slug}.png',scale=3)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
